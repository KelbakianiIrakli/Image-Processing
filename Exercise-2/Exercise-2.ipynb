{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7bb5de4",
   "metadata": {},
   "source": [
    "Student: Irakli Kelbakiani Email: Irakli.Kelbakiani@students.unibe.ch Github: https://github.com/KelbakianiIrakli/Image-Processing/tree/main/Exercise-2\n",
    "\n",
    "(a) Define a universal color table with a maximum of 256 different colors. I define 216 colors in a following way: for r in range(0, 256, 51): # Red channel values (0, 51, 102, 153, 204, 255) for g in range(0, 256, 51): # Green channel (0, 51, 102, 153, 204, 255) for b in range(0, 256, 51): # Blue channel (0, 51, 102, 153, 204, 255) color_table.append((r, g, b))\n",
    "\n",
    "Each of the three nested loops iterates over the red, green, and blue channels, respectively, with step increments of 51. Given this structure, we can calculate the total number of colors generated as follows: For the red channel (r), there are (256 - 0) / 51 + 1 possible values, which is 6 values (0, 51, 102, 153, 204, 255). For the green channel (g), there are also 6 possible values. For the blue channel (b), there are 6 possible values. So, as 666=216 I have total 216 colors defined.\n",
    "\n",
    "(b) Write an algorithm that transforms the initial pixel values with an index to the color table so that the return image looks as similar as possible to the original image. def find_closest_color_index(pixel, color_table): min_distance = float(\"inf\") closest_index = 0\n",
    "\n",
    "for i, color in enumerate(color_table):\n",
    "    # Calculate Euclidean distance between pixel and color\n",
    "    distance = sum((a - b) ** 2 for a, b in zip(pixel, color)) ** 0.5\n",
    "\n",
    "    if distance < min_distance:\n",
    "        min_distance = distance\n",
    "        closest_index = i\n",
    "\n",
    "return closest_index\n",
    "I created a function, in which we calculate Euclidean distance of this pixel and each color in color table. We will take value from the color map which has smallest distance.\n",
    "\n",
    "(c) Replace the universal color table by an adaptive colour table, which is optimized for the given input image. generate_adaptive_color_table(image, num_colors)- function generates an adaptive color table using K-Means clustering by extracting representative 256 colors from lena image.\n",
    "\n",
    "(d) Apply your two algorithms on the image ”Lena” which is on ILIAS. \n",
    "Please, see images in the same dir as this file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05946fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ed9f286a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "lena_image = Image.open(\"lena.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e2032",
   "metadata": {},
   "source": [
    "# Generate universal color table - 216 colors in total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d1ce8786",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_universal_color_table():\n",
    "    color_table = []\n",
    "\n",
    "    for r in range(0, 256, 51):  # Red channel values (0, 51, 102, 153, 204, 255)\n",
    "        for g in range(0, 256, 51):  # Green channel (0, 51, 102, 153, 204, 255)\n",
    "            for b in range(0, 256, 51):  # Blue channel (0, 51, 102, 153, 204, 255)\n",
    "                color_table.append((r, g, b))\n",
    "\n",
    "    return color_table\n",
    "\n",
    "# Generate the universal color table\n",
    "universal_color_table = generate_universal_color_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fcd4fa3",
   "metadata": {},
   "source": [
    "# make a png image for created colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5018c922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# color table image for better visualization\n",
    "def create_color_table_image(color_table, grid_size, cell_size):\n",
    "\n",
    "    image_width = grid_size[0] * cell_size\n",
    "    image_height = grid_size[1] * cell_size\n",
    "\n",
    "\n",
    "    image = Image.new(\"RGB\", (image_width, image_height), (255, 255, 255))\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "\n",
    "    font = ImageFont.load_default()\n",
    "    font_size = 9 \n",
    "    font = ImageFont.truetype(\"arial.ttf\", font_size) \n",
    "    for i, color in enumerate(color_table):\n",
    "        row = i // grid_size[0]\n",
    "        col = i % grid_size[0]\n",
    "        x = col * cell_size\n",
    "        y = row * cell_size\n",
    "        color_tuple = (color[0], color[1], color[2])\n",
    "        draw.rectangle([x, y, x + cell_size, y + cell_size], fill=color_tuple)\n",
    "        text_x = x + 2\n",
    "        text_y = y + 2\n",
    "        # use complementary color for each cell so that text is visible\n",
    "        text_color = (255 - color[0], 255 - color[1], 255 - color[2]) \n",
    "        draw.text((text_x, text_y), f\"{color}\", font=font, fill=text_color)\n",
    "\n",
    "    return image\n",
    "\n",
    "\n",
    "grid_size = (16, 16)  \n",
    "cell_size = 70\n",
    "\n",
    "# Generate the universal color table\n",
    "universal_color_table = generate_universal_color_table()\n",
    "\n",
    "# Create an image of the color table\n",
    "color_table_image = create_color_table_image(universal_color_table, grid_size, cell_size)\n",
    "\n",
    "color_table_image.save(\"universal_color_table.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e44461",
   "metadata": {},
   "source": [
    "# Find closest color index using Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f00aa6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest_color_index(pixel, color_table):\n",
    "    min_distance = float(\"inf\")\n",
    "    closest_index = 0\n",
    "\n",
    "    for i, color in enumerate(color_table):\n",
    "        # Calculate Euclidean distance between pixel and color\n",
    "        distance = sum((a - b) ** 2 for a, b in zip(pixel, color)) ** 0.5\n",
    "\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_index = i\n",
    "\n",
    "    return closest_index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd105b81",
   "metadata": {},
   "source": [
    "# Generate lena using universal color table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "febfebe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_to_color_table(image, color_table):\n",
    "    quantized_image = Image.new(\"P\", image.size)\n",
    "    \n",
    "    palette_bytes = bytes([value for color in color_table for value in color])\n",
    "    \n",
    "    quantized_image.putpalette(palette_bytes)\n",
    "    \n",
    "    for x in range(image.width):\n",
    "        for y in range(image.height):\n",
    "            pixel = image.getpixel((x, y))\n",
    "            index = find_closest_color_index(pixel, color_table)\n",
    "            quantized_image.putpixel((x, y), index)\n",
    "\n",
    "    return quantized_image\n",
    "\n",
    "universal_color_table_bytes = bytes([value for color in universal_color_table for value in color])\n",
    "\n",
    "quantized_lena = quantize_to_color_table(lena_image, universal_color_table)\n",
    "quantized_lena.putpalette(universal_color_table_bytes)  \n",
    "quantized_lena.save(\"lena_universal_color_table.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b9c4a82",
   "metadata": {},
   "source": [
    "# Generate adaptive color table using K-Means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "032c79ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use K-Means to identify suitable color table for this image\n",
    "# After training, the cluster centers represent the representative colors that K-Means has identified. \n",
    "# These cluster centers are extracted as the adaptive color table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8bb32e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "def generate_adaptive_color_table(image, num_colors):\n",
    "    pixel_data = np.array(image).reshape(-1, 3)\n",
    "\n",
    "    # Apply K-Means clustering to find representative colors\n",
    "    kmeans = KMeans(n_clusters=num_colors)\n",
    "    kmeans.fit(pixel_data)\n",
    "\n",
    "    adaptive_color_table = kmeans.cluster_centers_.astype(int)\n",
    "\n",
    "    return adaptive_color_table\n",
    "\n",
    "adaptive_color_table = generate_adaptive_color_table(lena_image, 256)\n",
    "grid_size = (16, 16)  \n",
    "cell_size = 70\n",
    "color_table_image = create_color_table_image(adaptive_color_table, grid_size, cell_size)\n",
    "color_table_image.save(\"adaptive_color_table.png\")\n",
    "quantized_lena_adaptive = quantize_to_color_table(lena_image, adaptive_color_table)\n",
    "quantized_lena_adaptive.save(\"lena_adaptive_color_table.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
